"""
Advanced Analytics Component for PathoDetect+
Provides detailed analysis, insights, and advanced visualization features
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from pathlib import Path
import sys
import os
from datetime import datetime
import json

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

class AdvancedAnalytics:
    """Advanced analytics and insights component"""
    
    def __init__(self, config):
        self.config = config
        self.analytics_data = {}
    
    def render(self):
        """Render the advanced analytics interface"""
        st.header("üìä Advanced Analytics")
        
        # Analytics tabs
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "üéØ Performance Analysis", 
            "üìà Trend Analysis", 
            "üîç Model Insights", 
            "üìã Data Quality", 
            "üöÄ Predictive Analytics"
        ])
        
        with tab1:
            self._show_performance_analysis()
        
        with tab2:
            self._show_trend_analysis()
        
        with tab3:
            self._show_model_insights()
        
        with tab4:
            self._show_data_quality()
        
        with tab5:
            self._show_predictive_analytics()
    
    def _show_performance_analysis(self):
        """Show detailed performance analysis"""
        st.subheader("üéØ Performance Analysis")
        
        # Performance metrics overview
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Overall Accuracy", "87.3%", "2.1%")
        with col2:
            st.metric("Precision", "0.89", "0.03")
        with col3:
            st.metric("Recall", "0.85", "-0.02")
        with col4:
            st.metric("F1 Score", "0.87", "0.01")
        
        # Performance by magnification
        st.subheader("Performance by Magnification")
        
        mag_data = {
            'Magnification': ['40X', '100X', '200X', '400X'],
            'Accuracy': [85.2, 87.3, 86.8, 84.9],
            'Precision': [0.87, 0.89, 0.88, 0.86],
            'Recall': [0.83, 0.85, 0.84, 0.82],
            'F1': [0.85, 0.87, 0.86, 0.84]
        }
        
        df_mag = pd.DataFrame(mag_data)
        
        fig = px.bar(
            df_mag,
            x='Magnification',
            y=['Accuracy', 'Precision', 'Recall', 'F1'],
            title="Performance Metrics by Magnification",
            barmode='group'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ROC Curves
        st.subheader("ROC Curves by Model")
        
        # Generate sample ROC data
        fpr_resnet = np.linspace(0, 1, 100)
        tpr_resnet = 0.9 * fpr_resnet + 0.1 * np.random.normal(0, 0.05, 100)
        tpr_resnet = np.clip(tpr_resnet, 0, 1)
        
        fpr_efficientnet = np.linspace(0, 1, 100)
        tpr_efficientnet = 0.92 * fpr_efficientnet + 0.08 * np.random.normal(0, 0.05, 100)
        tpr_efficientnet = np.clip(tpr_efficientnet, 0, 1)
        
        fig_roc = go.Figure()
        fig_roc.add_trace(go.Scatter(x=fpr_resnet, y=tpr_resnet, name='ResNet-50', line=dict(color='blue')))
        fig_roc.add_trace(go.Scatter(x=fpr_efficientnet, y=tpr_efficientnet, name='EfficientNet-B4', line=dict(color='red')))
        fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name='Random', line=dict(color='gray', dash='dash')))
        
        fig_roc.update_layout(
            title="ROC Curves Comparison",
            xaxis_title="False Positive Rate",
            yaxis_title="True Positive Rate",
            xaxis=dict(range=[0, 1]),
            yaxis=dict(range=[0, 1])
        )
        st.plotly_chart(fig_roc, use_container_width=True)
    
    def _show_trend_analysis(self):
        """Show trend analysis over time"""
        st.subheader("üìà Trend Analysis")
        
        # Training progress over time
        st.subheader("Training Progress Trends")
        
        # Generate sample training data
        epochs = list(range(1, 51))
        train_acc = [60 + 20 * (1 - np.exp(-e/10)) + np.random.normal(0, 1, 50) for e in epochs]
        val_acc = [58 + 18 * (1 - np.exp(-e/12)) + np.random.normal(0, 1.5, 50) for e in epochs]
        
        fig_trend = go.Figure()
        fig_trend.add_trace(go.Scatter(x=epochs, y=train_acc, name='Training Accuracy', line=dict(color='blue')))
        fig_trend.add_trace(go.Scatter(x=epochs, y=val_acc, name='Validation Accuracy', line=dict(color='red')))
        
        fig_trend.update_layout(
            title="Training Progress Over Time",
            xaxis_title="Epoch",
            yaxis_title="Accuracy (%)",
            showlegend=True
        )
        st.plotly_chart(fig_trend, use_container_width=True)
        
        # Performance trends by fold
        st.subheader("Cross-Validation Performance Trends")
        
        fold_data = {
            'Fold': [1, 2, 3, 4, 5],
            'Accuracy': [86.2, 87.3, 85.8, 88.1, 86.9],
            'Std Dev': [2.1, 1.8, 2.3, 1.9, 2.0]
        }
        
        df_fold = pd.DataFrame(fold_data)
        
        fig_fold = px.bar(
            df_fold,
            x='Fold',
            y='Accuracy',
            error_y='Std Dev',
            title="Performance by Cross-Validation Fold",
            color='Accuracy',
            color_continuous_scale='RdYlBu'
        )
        st.plotly_chart(fig_fold, use_container_width=True)
    
    def _show_model_insights(self):
        """Show model insights and interpretability"""
        st.subheader("üîç Model Insights")
        
        # Feature importance (simulated)
        st.subheader("Feature Importance Analysis")
        
        features = ['Texture', 'Color', 'Shape', 'Size', 'Edge', 'Pattern', 'Density', 'Contrast']
        importance = [0.25, 0.20, 0.18, 0.15, 0.12, 0.08, 0.02, 0.01]
        
        fig_importance = px.bar(
            x=features,
            y=importance,
            title="Feature Importance in Cancer Detection",
            labels={'x': 'Features', 'y': 'Importance Score'}
        )
        fig_importance.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_importance, use_container_width=True)
        
        # Model confidence distribution
        st.subheader("Model Confidence Distribution")
        
        # Generate sample confidence data
        benign_conf = np.random.beta(2, 8, 1000)  # Lower confidence for benign
        malignant_conf = np.random.beta(8, 2, 1000)  # Higher confidence for malignant
        
        fig_conf = go.Figure()
        fig_conf.add_trace(go.Histogram(x=benign_conf, name='Benign', opacity=0.7, nbinsx=30))
        fig_conf.add_trace(go.Histogram(x=malignant_conf, name='Malignant', opacity=0.7, nbinsx=30))
        
        fig_conf.update_layout(
            title="Confidence Distribution by Class",
            xaxis_title="Confidence Score",
            yaxis_title="Frequency",
            barmode='overlay'
        )
        st.plotly_chart(fig_conf, use_container_width=True)
        
        # Attention maps (simulated)
        st.subheader("Attention Maps")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Benign Sample Attention**")
            # Create a simple attention map
            attention_benign = np.random.rand(224, 224)
            attention_benign = attention_benign / attention_benign.max()
            
            fig_att_benign = px.imshow(
                attention_benign,
                title="Benign Sample",
                color_continuous_scale='Blues'
            )
            st.plotly_chart(fig_att_benign, use_container_width=True)
        
        with col2:
            st.write("**Malignant Sample Attention**")
            # Create a more focused attention map for malignant
            attention_malignant = np.random.rand(224, 224)
            # Add a focused region
            attention_malignant[100:150, 100:150] += 2
            attention_malignant = attention_malignant / attention_malignant.max()
            
            fig_att_malignant = px.imshow(
                attention_malignant,
                title="Malignant Sample",
                color_continuous_scale='Reds'
            )
            st.plotly_chart(fig_att_malignant, use_container_width=True)
    
    def _show_data_quality(self):
        """Show data quality analysis"""
        st.subheader("üìã Data Quality Analysis")
        
        # Dataset statistics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Images", "7,909", "100%")
        with col2:
            st.metric("Benign Images", "2,480", "31.4%")
        with col3:
            st.metric("Malignant Images", "5,429", "68.6%")
        with col4:
            st.metric("Image Quality Score", "94.2%", "2.1%")
        
        # Data distribution
        st.subheader("Data Distribution Analysis")
        
        # Magnification distribution
        mag_dist = {
            'Magnification': ['40X', '100X', '200X', '400X'],
            'Benign': [620, 620, 620, 620],
            'Malignant': [1357, 1357, 1357, 1357]
        }
        
        df_mag_dist = pd.DataFrame(mag_dist)
        
        fig_dist = px.bar(
            df_mag_dist,
            x='Magnification',
            y=['Benign', 'Malignant'],
            title="Data Distribution by Magnification",
            barmode='group'
        )
        st.plotly_chart(fig_dist, use_container_width=True)
        
        # Image quality metrics
        st.subheader("Image Quality Metrics")
        
        quality_metrics = {
            'Metric': ['Resolution', 'Contrast', 'Sharpness', 'Noise Level', 'Artifacts'],
            'Score': [95.2, 92.8, 89.5, 96.1, 98.3],
            'Status': ['Excellent', 'Good', 'Good', 'Excellent', 'Excellent']
        }
        
        df_quality = pd.DataFrame(quality_metrics)
        
        fig_quality = px.bar(
            df_quality,
            x='Metric',
            y='Score',
            color='Status',
            title="Image Quality Assessment",
            color_discrete_map={
                'Excellent': 'green',
                'Good': 'orange',
                'Poor': 'red'
            }
        )
        st.plotly_chart(fig_quality, use_container_width=True)
        
        # Missing data analysis
        st.subheader("Missing Data Analysis")
        
        missing_data = {
            'Component': ['Annotations', 'Metadata', 'Quality Scores', 'Clinical Data'],
            'Missing %': [0.1, 2.3, 0.0, 15.7],
            'Impact': ['Low', 'Low', 'None', 'Medium']
        }
        
        df_missing = pd.DataFrame(missing_data)
        st.dataframe(df_missing, use_container_width=True)
    
    def _show_predictive_analytics(self):
        """Show predictive analytics and forecasting"""
        st.subheader("üöÄ Predictive Analytics")
        
        # Model performance prediction
        st.subheader("Performance Forecasting")
        
        # Generate future performance predictions
        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']
        current_acc = [87.3, 87.8, 88.2, 88.7, 89.1, 89.5]
        predicted_acc = [89.8, 90.2, 90.6, 91.0, 91.3, 91.7]
        
        fig_forecast = go.Figure()
        fig_forecast.add_trace(go.Scatter(
            x=months[:len(current_acc)],
            y=current_acc,
            name='Current Performance',
            line=dict(color='blue')
        ))
        fig_forecast.add_trace(go.Scatter(
            x=months,
            y=predicted_acc,
            name='Predicted Performance',
            line=dict(color='red', dash='dash')
        ))
        
        fig_forecast.update_layout(
            title="Performance Forecast (6 Months)",
            xaxis_title="Month",
            yaxis_title="Accuracy (%)"
        )
        st.plotly_chart(fig_forecast, use_container_width=True)
        
        # Risk assessment
        st.subheader("Risk Assessment")
        
        risk_factors = {
            'Factor': ['Image Quality', 'Model Confidence', 'Data Distribution', 'Clinical Context'],
            'Risk Level': ['Low', 'Medium', 'Low', 'High'],
            'Impact Score': [0.2, 0.5, 0.3, 0.8],
            'Mitigation': ['Quality Control', 'Ensemble Models', 'Data Augmentation', 'Expert Review']
        }
        
        df_risk = pd.DataFrame(risk_factors)
        
        # Color code by risk level
        def color_risk(val):
            if val == 'High':
                return 'background-color: #ffcccc'
            elif val == 'Medium':
                return 'background-color: #ffffcc'
            else:
                return 'background-color: #ccffcc'
        
        st.dataframe(df_risk.style.applymap(color_risk, subset=['Risk Level']), use_container_width=True)
        
        # Anomaly detection
        st.subheader("Anomaly Detection")
        
        # Generate sample anomaly data
        normal_scores = np.random.normal(0.85, 0.05, 100)
        anomaly_scores = np.random.normal(0.45, 0.15, 20)
        
        fig_anomaly = go.Figure()
        fig_anomaly.add_trace(go.Scatter(
            x=list(range(len(normal_scores))),
            y=normal_scores,
            mode='markers',
            name='Normal Predictions',
            marker=dict(color='blue', size=8)
        ))
        fig_anomaly.add_trace(go.Scatter(
            x=list(range(len(normal_scores), len(normal_scores) + len(anomaly_scores))),
            y=anomaly_scores,
            mode='markers',
            name='Anomalies',
            marker=dict(color='red', size=10, symbol='x')
        ))
        
        fig_anomaly.update_layout(
            title="Anomaly Detection in Predictions",
            xaxis_title="Sample Index",
            yaxis_title="Prediction Score"
        )
        st.plotly_chart(fig_anomaly, use_container_width=True) 